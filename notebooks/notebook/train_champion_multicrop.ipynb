{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "750fdae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ee92b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation.farm_env import FarmEnv\n",
    "from simulation.env_wrapper import MultiAgentActionWrapper\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aca0173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Configuration: SET THE CROP AND MODEL NAME HERE ---\n",
    "\n",
    "# -- CROP TO TRAIN --\n",
    "# Change this to \"Rice\" or \"Sugarcane\" to train those models.\n",
    "CROP_TYPE = \"Wheat\" \n",
    "# Corresponding location for weather data\n",
    "# For Rice: 22.5726 (Kolkata), For Sugarcane: 26.8467 (Lucknow)\n",
    "LATITUDE = 30.9010 # Ludhiana for Wheat\n",
    "LONGITUDE = 75.8573"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42c7abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our most advanced environment. It requires a very long training run.\n",
    "TRAINING_STEPS = 3000000 # 3 Million steps is a solid target\n",
    "MODEL_NAME = f\"ppo_{CROP_TYPE.upper()}_expert.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef2d1cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- DIRECTORIES --\n",
    "models_dir = \"../models\"\n",
    "logs_dir = f\"../logs/{CROP_TYPE.lower()}_champion_logs/\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(logs_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1324c412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating environment for CROP: Wheat ---\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- Creating environment for CROP: {CROP_TYPE} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88dce3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create the environment. This is good practice.\n",
    "def make_env():\n",
    "    # Pass the crop type to the environment constructor\n",
    "    env = FarmEnv(crop_type=CROP_TYPE) \n",
    "    # The wrapper is essential to handle the multi-action space\n",
    "    env = MultiAgentActionWrapper(env)\n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1de91191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching real weather data for Lat: 30.901, Long: 75.8573 from Open-Meteo...\n",
      "Sucessfully fetched and processed real weather data from Open-Meteo.\n",
      "Environment ready for training.\n"
     ]
    }
   ],
   "source": [
    "# Create the wrapped environment\n",
    "wrapped_env = make_env()\n",
    "print(\"Environment ready for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d8d25e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model Definition with a More Powerful Brain ---\n",
    "\n",
    "# A larger neural network is needed for the complex observations\n",
    "policy_kwargs = dict(net_arch=dict(pi=[256, 128], vf=[256, 128]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4010aba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# We will use advanced PPO parameters for more stable training on this complex task\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    wrapped_env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=1,\n",
    "    tensorboard_log=logs_dir,\n",
    "    learning_rate=0.0001,  # A smaller learning rate is often better for complex tasks\n",
    "    n_steps=4096,          # Collect more experience before each update\n",
    "    batch_size=128,        # Process updates in smaller batches\n",
    "    gamma=0.99,            # Emphasize long-term rewards\n",
    "    gae_lambda=0.95\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32db407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Training\n",
    "\n",
    "# Set up a callback to save the model periodically\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "  save_freq=100000, # Save a checkpoint every 100,000 steps\n",
    "  save_path=os.path.join(logs_dir, 'checkpoints'),\n",
    "  name_prefix=f\"{CROP_TYPE.lower()}_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe4cfebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting CHAMPION training for Wheat ---\n",
      "Total timesteps: 3000000\n",
      "To view live training graphs, open a new terminal and run:\n",
      "tensorboard --logdir /Users/aadarshraj/Documents/ai_project/digital_twin_farm/logs/wheat_champion_logs\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Starting CHAMPION training for {CROP_TYPE} ---\")\n",
    "print(f\"Total timesteps: {TRAINING_STEPS}\")\n",
    "print(f\"To view live training graphs, open a new terminal and run:\")\n",
    "print(f\"tensorboard --logdir {os.path.abspath(logs_dir)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1270f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training process\n",
    "model.learn(\n",
    "    total_timesteps=TRAINING_STEPS,\n",
    "    tb_log_name=f\"PPO_Champion_{CROP_TYPE}\",\n",
    "    callback=checkpoint_callback\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1a7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save the Final Model ---\n",
    "\n",
    "final_model_path = os.path.join(models_dir, MODEL_NAME)\n",
    "model.save(final_model_path)\n",
    "\n",
    "print(f\"\\n--- CHAMPION Training Complete! ---\")\n",
    "print(f\"The definitive model for {CROP_TYPE} is saved at: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625492c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
