{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c623dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader \n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78385f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from simulation.data_loader import get_weather_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7394f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### configuration: uNCOMMENT the locatoin you want to train\n",
    "\n",
    "#### Ludhiana, Punjab (for Wheat) \n",
    "LOCATION_NAME = \"Ludhiana\"\n",
    "LATITUDE = 30.9010\n",
    "LONGITUDE = 75.8573\n",
    "\n",
    "##### Aurangabad, Bihar (for Rice) \n",
    "# LOCATION_NAME = \"Aurangabad\"\n",
    "# LATITUDE = 24.75\n",
    "# LONGITUDE = 84.37\n",
    "\n",
    "#### Kolkata, West Bengal (for Rice)\n",
    "# LOCATION_NAME = \"Kolkata\"\n",
    "# LATITUDE = 22.5726\n",
    "# LONGITUDE = 88.3639\n",
    "\n",
    "#### Lucknow, Uttar Pradesh (for Sugarcane) \n",
    "# LOCATION_NAME = \"Lucknow\"\n",
    "# LATITUDE = 26.8467\n",
    "# LONGITUDE = 80.9462\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0a346cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Training Parameters \n",
    "NUM_MODELS_IN_ENSEMBLE = 5\n",
    "EPOCHS_PER_MODEL = 100\n",
    "LOOK_BACK = 30\n",
    "LOOK_FORWARD = 7\n",
    "BATCH_SIZE = 64\n",
    "NUM_FEATURES = 4 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14839f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Dynamic File Naming\n",
    "models_dir = \"../models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "# The saved files will now include the location name for easy identification\n",
    "SCALER_PATH = os.path.join(models_dir, f\"advanced_weather_data_scaler_{LOCATION_NAME.lower()}.pkl\")\n",
    "MODEL_SAVE_PREFIX = f\"lstm_advanced_weather_forecaster_{LOCATION_NAME.lower()}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c58a06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Fetching and Preparing Data for Ludhiana ---\n",
      "Fetching ADVANCED weather data for Lat: 30.901, Long: 75.8573 from Open-Meteo...\n",
      "Successfully fetched and processed advanced weather data.\n",
      "Data scaler for Ludhiana has been fit and saved to: ../models/advanced_weather_data_scaler_ludhiana.pkl\n"
     ]
    }
   ],
   "source": [
    "#### Data Preparation \n",
    "print(f\"--- Step 1: Fetching and Preparing Data for {LOCATION_NAME} ---\")\n",
    "full_weather_data = get_weather_data(latitude=LATITUDE, longitude=LONGITUDE, start_date=\"2010-01-01\", end_date=\"2022-12-31\")\n",
    "if full_weather_data is None: raise Exception(\"Failed to fetch advanced weather data.\")\n",
    "weather_values = full_weather_data[['temperature', 'rainfall', 'humidity', 'wind_speed']].values.astype(np.float32)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_weather_data = scaler.fit_transform(weather_values)\n",
    "with open(SCALER_PATH, 'wb') as f: pickle.dump(scaler, f)\n",
    "print(f\"Data scaler for {LOCATION_NAME} has been fit and saved to: {SCALER_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad795405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create Sequences \n",
    "def create_sequences(data, look_back=30, look_forward=7):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back - look_forward + 1):\n",
    "        X.append(data[i:(i + look_back)])\n",
    "        y.append(data[(i + look_back):(i + look_back + look_forward)])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_full, y_full = create_sequences(scaled_weather_data, LOOK_BACK, LOOK_FORWARD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "948b6d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Define LSTM Model Architecture\n",
    "class AdvancedWeatherLSTM(nn.Module):\n",
    "    def __init__(self, input_size=NUM_FEATURES, hidden_layer_size=128, output_size=NUM_FEATURES, num_layers=2, look_forward=7):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers, batch_first=True, dropout=0.1)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size * look_forward)\n",
    "        self.look_forward = look_forward\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, _ = self.lstm(input_seq)\n",
    "        predictions = self.linear(lstm_out[:, -1, :])\n",
    "        return predictions.view(-1, self.look_forward, NUM_FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a454011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 2: Starting Ensemble Training for 5 Models for Ludhiana ---\n",
      "Training on device: cpu\n",
      "\n",
      "--- Training Model 1/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aadarshraj/ai_env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 1 - Epoch 10/100 | Train Loss: 0.006853 | Val Loss: 0.006526\n",
      "  Model 1 - Epoch 20/100 | Train Loss: 0.006323 | Val Loss: 0.005989\n",
      "  Model 1 - Epoch 30/100 | Train Loss: 0.006202 | Val Loss: 0.005862\n",
      "  Model 1 - Epoch 40/100 | Train Loss: 0.005905 | Val Loss: 0.005635\n",
      "  Model 1 - Epoch 50/100 | Train Loss: 0.005827 | Val Loss: 0.005571\n",
      "  Model 1 - Epoch 60/100 | Train Loss: 0.005763 | Val Loss: 0.005501\n",
      "  Model 1 - Epoch 70/100 | Train Loss: 0.005756 | Val Loss: 0.005522\n",
      "  Model 1 - Epoch 80/100 | Train Loss: 0.005721 | Val Loss: 0.005659\n",
      "  Model 1 - Epoch 90/100 | Train Loss: 0.005662 | Val Loss: 0.005380\n",
      "  Model 1 - Epoch 100/100 | Train Loss: 0.005652 | Val Loss: 0.005411\n",
      "Successfully trained and saved model 1 to: ../models/lstm_advanced_weather_forecaster_ludhiana_1.pth\n",
      "\n",
      "--- Training Model 2/5 ---\n",
      "  Model 2 - Epoch 10/100 | Train Loss: 0.006706 | Val Loss: 0.006778\n",
      "  Model 2 - Epoch 20/100 | Train Loss: 0.006254 | Val Loss: 0.006131\n",
      "  Model 2 - Epoch 30/100 | Train Loss: 0.006041 | Val Loss: 0.006137\n",
      "  Model 2 - Epoch 40/100 | Train Loss: 0.005830 | Val Loss: 0.005866\n",
      "  Model 2 - Epoch 50/100 | Train Loss: 0.005683 | Val Loss: 0.005813\n",
      "  Model 2 - Epoch 60/100 | Train Loss: 0.005578 | Val Loss: 0.005669\n",
      "  Model 2 - Epoch 70/100 | Train Loss: 0.005508 | Val Loss: 0.005688\n",
      "  Model 2 - Epoch 80/100 | Train Loss: 0.005383 | Val Loss: 0.005559\n",
      "  Model 2 - Epoch 90/100 | Train Loss: 0.005324 | Val Loss: 0.005525\n",
      "  Model 2 - Epoch 100/100 | Train Loss: 0.005283 | Val Loss: 0.005490\n",
      "Successfully trained and saved model 2 to: ../models/lstm_advanced_weather_forecaster_ludhiana_2.pth\n",
      "\n",
      "--- Training Model 3/5 ---\n",
      "  Model 3 - Epoch 10/100 | Train Loss: 0.006546 | Val Loss: 0.006718\n",
      "  Model 3 - Epoch 20/100 | Train Loss: 0.006171 | Val Loss: 0.006393\n",
      "  Model 3 - Epoch 30/100 | Train Loss: 0.005863 | Val Loss: 0.006153\n",
      "  Model 3 - Epoch 40/100 | Train Loss: 0.005592 | Val Loss: 0.005792\n",
      "  Model 3 - Epoch 50/100 | Train Loss: 0.005512 | Val Loss: 0.005907\n",
      "  Model 3 - Epoch 60/100 | Train Loss: 0.005386 | Val Loss: 0.005578\n",
      "  Model 3 - Epoch 70/100 | Train Loss: 0.005317 | Val Loss: 0.005540\n",
      "  Model 3 - Epoch 80/100 | Train Loss: 0.005257 | Val Loss: 0.005566\n",
      "  Model 3 - Epoch 90/100 | Train Loss: 0.005221 | Val Loss: 0.005499\n",
      "  Model 3 - Epoch 100/100 | Train Loss: 0.005174 | Val Loss: 0.005477\n",
      "Successfully trained and saved model 3 to: ../models/lstm_advanced_weather_forecaster_ludhiana_3.pth\n",
      "\n",
      "--- Training Model 4/5 ---\n",
      "  Model 4 - Epoch 10/100 | Train Loss: 0.006859 | Val Loss: 0.006576\n",
      "  Model 4 - Epoch 20/100 | Train Loss: 0.006394 | Val Loss: 0.006214\n",
      "  Model 4 - Epoch 30/100 | Train Loss: 0.006094 | Val Loss: 0.005825\n",
      "  Model 4 - Epoch 40/100 | Train Loss: 0.005958 | Val Loss: 0.005782\n",
      "  Model 4 - Epoch 50/100 | Train Loss: 0.005877 | Val Loss: 0.005699\n",
      "  Model 4 - Epoch 60/100 | Train Loss: 0.005853 | Val Loss: 0.005643\n",
      "  Model 4 - Epoch 70/100 | Train Loss: 0.005733 | Val Loss: 0.005562\n",
      "  Model 4 - Epoch 80/100 | Train Loss: 0.005601 | Val Loss: 0.005411\n",
      "  Model 4 - Epoch 90/100 | Train Loss: 0.005491 | Val Loss: 0.005287\n",
      "  Model 4 - Epoch 100/100 | Train Loss: 0.005272 | Val Loss: 0.005177\n",
      "Successfully trained and saved model 4 to: ../models/lstm_advanced_weather_forecaster_ludhiana_4.pth\n",
      "\n",
      "--- Training Model 5/5 ---\n",
      "  Model 5 - Epoch 10/100 | Train Loss: 0.006770 | Val Loss: 0.007517\n",
      "  Model 5 - Epoch 20/100 | Train Loss: 0.006171 | Val Loss: 0.006727\n",
      "  Model 5 - Epoch 30/100 | Train Loss: 0.005916 | Val Loss: 0.006290\n",
      "  Model 5 - Epoch 40/100 | Train Loss: 0.005771 | Val Loss: 0.006121\n",
      "  Model 5 - Epoch 50/100 | Train Loss: 0.005552 | Val Loss: 0.006035\n",
      "  Model 5 - Epoch 60/100 | Train Loss: 0.005423 | Val Loss: 0.006153\n",
      "  Model 5 - Epoch 70/100 | Train Loss: 0.005328 | Val Loss: 0.005699\n",
      "  Model 5 - Epoch 80/100 | Train Loss: 0.005101 | Val Loss: 0.005601\n",
      "  Model 5 - Epoch 90/100 | Train Loss: 0.004729 | Val Loss: 0.005214\n",
      "  Model 5 - Epoch 100/100 | Train Loss: 0.004624 | Val Loss: 0.005173\n",
      "Successfully trained and saved model 5 to: ../models/lstm_advanced_weather_forecaster_ludhiana_5.pth\n",
      "\n",
      "--- Ensemble Training for Ludhiana Complete! ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#### The Ensemble Training Loop \n",
    "print(f\"\\n--- Step 2: Starting Ensemble Training for {NUM_MODELS_IN_ENSEMBLE} Models for {LOCATION_NAME} ---\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Training on device: {device}\")\n",
    "\n",
    "saved_model_paths = []\n",
    "for model_idx in range(1, NUM_MODELS_IN_ENSEMBLE + 1):\n",
    "    print(f\"\\n--- Training Model {model_idx}/{NUM_MODELS_IN_ENSEMBLE} ---\")\n",
    "    \n",
    "    X_sample, y_sample = resample(X_full, y_full, replace=True, n_samples=len(X_full))\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
    "    \n",
    "    train_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "    val_dataset = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = AdvancedWeatherLSTM().to(device)\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5, verbose=False)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    for epoch in range(EPOCHS_PER_MODEL):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for sequences, labels in train_loader:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(sequences)\n",
    "            loss = loss_function(y_pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in val_loader:\n",
    "                sequences, labels = sequences.to(device), labels.to(device)\n",
    "                y_pred = model(sequences)\n",
    "                loss = loss_function(y_pred, labels)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'  Model {model_idx} - Epoch {epoch+1}/{EPOCHS_PER_MODEL} | Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}')\n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_path = os.path.join(models_dir, f\"{MODEL_SAVE_PREFIX}_{model_idx}.pth\")\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(f\"--- Early stopping triggered at epoch {epoch+1} ---\")\n",
    "            break\n",
    "            \n",
    "    print(f\"Successfully trained and saved model {model_idx} to: {best_model_path}\")\n",
    "    saved_model_paths.append(best_model_path)\n",
    "\n",
    "print(f\"\\n--- Ensemble Training for {LOCATION_NAME} Complete! ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43274d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
